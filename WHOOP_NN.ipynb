{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vM09eKelTm63T7MqqUbC8DF89jQm5hiv",
      "authorship_tag": "ABX9TyMwD4eQ+fktG+2z1R0Y6Hw5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscoerramuspe/masters_thesis/blob/main/WHOOP_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "vo_5-Qhgr_Yn",
        "outputId": "982837de-a65f-4f9e-f9d8-8b18134bfa18"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_C' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7954568b944c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mraise\u001b[0m  \u001b[0;31m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
          ]
        }
      ],
      "source": [
        "import torch as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 10bbWtKE3n1BpAYitwQxeQdfXYvpXhacZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCWjaGmtuQ4_",
        "outputId": "35430620-c282-4f1b-987d-494807175c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10bbWtKE3n1BpAYitwQxeQdfXYvpXhacZ\n",
            "To: /content/Final_Labeled_Scored_Data.xlsx\n",
            "100% 20.3M/20.3M [00:00<00:00, 24.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/Final_Labeled_Scored_Data.xlsx'"
      ],
      "metadata": {
        "id": "5lzY0mt0zK-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b7MWw3OB5RbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/Final_Labeled_Scored_Data.xlsx'\n",
        "df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "rcm9z7k1zNED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Print DataFrame info\n",
        "print(\"DataFrame shape:\", df.shape)\n",
        "print(\"\\nNaN values in each column:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Create a 'physical_capability' column if it doesn't exist\n",
        "if 'physical_capability' not in df.columns:\n",
        "    df['physical_capability'] = df['Recovery score %'].fillna(0) * 0.5 + \\\n",
        "                                df['Sleep efficiency %_x'].fillna(0) * 0.3 + \\\n",
        "                                df['Average HR (bpm)_x'].fillna(0).clip(upper=100) * 0.2\n",
        "\n",
        "numerical_columns = ['Activity Strain', 'Altitude change (meters)', 'Altitude gain (meters)',\n",
        "                     'Asleep duration (min)_x', 'Asleep duration (min)_y', 'Average HR (bpm)_x',\n",
        "                     'Average HR (bpm)_y', 'Awake duration (min)_x', 'Awake duration (min)_y',\n",
        "                     'Blood oxygen %', 'Day Strain', 'Deep (SWS) duration (min)_x',\n",
        "                     'Deep (SWS) duration (min)_y', 'Distance (meters)', 'Duration (min)',\n",
        "                     'Energy burned (cal)_x', 'Energy burned (cal)_y', 'HR Zone 1 %', 'HR Zone 2 %',\n",
        "                     'HR Zone 3 %', 'HR Zone 4 %', 'HR Zone 5 %', 'Heart rate variability (ms)',\n",
        "                     'In bed duration (min)_x', 'In bed duration (min)_y', 'Light sleep duration (min)_x',\n",
        "                     'Light sleep duration (min)_y', 'Max HR (bpm)_x', 'Max HR (bpm)_y',\n",
        "                     'REM duration (min)_x', 'REM duration (min)_y', 'Recovery score %',\n",
        "                     'Respiratory rate (rpm)_x', 'Respiratory rate (rpm)_y', 'Resting heart rate (bpm)',\n",
        "                     'Skin temp (celsius)', 'Sleep consistency %_x', 'Sleep consistency %_y',\n",
        "                     'Sleep debt (min)_x', 'Sleep debt (min)_y', 'Sleep efficiency %_x',\n",
        "                     'Sleep efficiency %_y', 'Sleep need (min)_x', 'Sleep need (min)_y',\n",
        "                     'Sleep performance %_x', 'Sleep performance %_y', 'Jump - Jump Height (in)_x',\n",
        "                     'Jump - Jump Height (in)_y']\n",
        "\n",
        "# Fill NaN values with column means\n",
        "for col in numerical_columns + ['physical_capability']:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "sequence_length = min(7, len(df) - 1)\n",
        "\n",
        "def create_sequences(data):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        seq = data.iloc[i:i+sequence_length][numerical_columns].values\n",
        "        target = data.iloc[i+sequence_length]['physical_capability']\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "    return torch.FloatTensor(sequences), torch.FloatTensor(targets)\n",
        "\n",
        "X, y = create_sequences(df)\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(f\"No valid sequences created. DataFrame has {len(df)} rows, using sequence length {sequence_length}.\")\n",
        "\n",
        "print(f\"Created {len(X)} sequences\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        out = self.sigmoid(out) * 100  # Scale output to 0-100\n",
        "        return out\n",
        "\n",
        "# Initialize the model\n",
        "input_size = len(numerical_columns)\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 1\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y.unsqueeze(1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test)\n",
        "        val_loss = criterion(val_outputs, y_test.unsqueeze(1))\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_output = model(X_test)\n",
        "    print(\"Predicted physical capability percentages:\", test_output.numpy().flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9hGy7baysGD",
        "outputId": "a6f17a5b-dae9-4666-fc5c-3fdd9233f344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (82811, 89)\n",
            "\n",
            "NaN values in each column:\n",
            "Activity Strain              10087\n",
            "Activity name                10087\n",
            "Altitude change (meters)     61839\n",
            "Altitude gain (meters)       61839\n",
            "Answered yes                  6620\n",
            "                             ...  \n",
            "What is your gender?           725\n",
            "Scan Date_x                   5559\n",
            "Jump - Jump Height (in)_x     5748\n",
            "Scan Date_y                  82694\n",
            "Jump - Jump Height (in)_y    82694\n",
            "Length: 89, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c7febf861c9e>:55: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  return torch.FloatTensor(sequences), torch.FloatTensor(targets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 82804 sequences\n",
            "Epoch [1/100], Loss: 1.0625, Val Loss: 0.9990\n",
            "Epoch [2/100], Loss: 0.4043, Val Loss: 0.7164\n",
            "Epoch [3/100], Loss: 0.2231, Val Loss: 0.6571\n",
            "Epoch [4/100], Loss: 0.0128, Val Loss: 0.5940\n",
            "Epoch [5/100], Loss: 0.1006, Val Loss: 0.5956\n",
            "Epoch [6/100], Loss: 0.0211, Val Loss: 0.5986\n",
            "Epoch [7/100], Loss: 0.1212, Val Loss: 0.6058\n",
            "Epoch [8/100], Loss: 0.0710, Val Loss: 0.6006\n",
            "Epoch [9/100], Loss: 0.0094, Val Loss: 0.5963\n",
            "Epoch [10/100], Loss: 0.2254, Val Loss: 0.6158\n",
            "Epoch [11/100], Loss: 0.2006, Val Loss: 0.6263\n",
            "Epoch [12/100], Loss: 0.1615, Val Loss: 0.5951\n",
            "Epoch [13/100], Loss: 0.0437, Val Loss: 0.6315\n",
            "Epoch [14/100], Loss: 0.0471, Val Loss: 0.6207\n",
            "Epoch [15/100], Loss: 0.0303, Val Loss: 0.6185\n",
            "Epoch [16/100], Loss: 0.1826, Val Loss: 0.6234\n",
            "Epoch [17/100], Loss: 0.0512, Val Loss: 0.6057\n",
            "Epoch [18/100], Loss: 0.0007, Val Loss: 0.6443\n",
            "Epoch [19/100], Loss: 0.2842, Val Loss: 0.6208\n",
            "Epoch [20/100], Loss: 0.0548, Val Loss: 0.6108\n",
            "Epoch [21/100], Loss: 0.0115, Val Loss: 0.6043\n",
            "Epoch [22/100], Loss: 0.4807, Val Loss: 0.6081\n",
            "Epoch [23/100], Loss: 0.0448, Val Loss: 0.6077\n",
            "Epoch [24/100], Loss: 0.0081, Val Loss: 0.6199\n",
            "Epoch [25/100], Loss: 0.0712, Val Loss: 0.6079\n",
            "Epoch [26/100], Loss: 0.0737, Val Loss: 0.6155\n",
            "Epoch [27/100], Loss: 0.0147, Val Loss: 0.6173\n",
            "Epoch [28/100], Loss: 0.0229, Val Loss: 0.6203\n",
            "Epoch [29/100], Loss: 0.2307, Val Loss: 0.6275\n",
            "Epoch [30/100], Loss: 0.1621, Val Loss: 0.5892\n",
            "Epoch [31/100], Loss: 0.6812, Val Loss: 0.6032\n",
            "Epoch [32/100], Loss: 0.0625, Val Loss: 0.6238\n",
            "Epoch [33/100], Loss: 0.1699, Val Loss: 0.6221\n",
            "Epoch [34/100], Loss: 0.1423, Val Loss: 0.6099\n",
            "Epoch [35/100], Loss: 0.0802, Val Loss: 0.6204\n",
            "Epoch [36/100], Loss: 0.0870, Val Loss: 0.6062\n",
            "Epoch [37/100], Loss: 0.3199, Val Loss: 0.6164\n",
            "Epoch [38/100], Loss: 0.0522, Val Loss: 0.6117\n",
            "Epoch [39/100], Loss: 0.1075, Val Loss: 0.6235\n",
            "Epoch [40/100], Loss: 0.0394, Val Loss: 0.6120\n",
            "Epoch [41/100], Loss: 0.0494, Val Loss: 0.5986\n",
            "Epoch [42/100], Loss: 0.0792, Val Loss: 0.6385\n",
            "Epoch [43/100], Loss: 0.0221, Val Loss: 0.6581\n",
            "Epoch [44/100], Loss: 0.0105, Val Loss: 0.6404\n",
            "Epoch [45/100], Loss: 0.0171, Val Loss: 0.6062\n",
            "Epoch [46/100], Loss: 0.0689, Val Loss: 0.6158\n",
            "Epoch [47/100], Loss: 0.0828, Val Loss: 0.6184\n",
            "Epoch [48/100], Loss: 0.0288, Val Loss: 0.6094\n",
            "Epoch [49/100], Loss: 0.0489, Val Loss: 0.6194\n",
            "Epoch [50/100], Loss: 0.0180, Val Loss: 0.6181\n",
            "Epoch [51/100], Loss: 0.0158, Val Loss: 0.6248\n",
            "Epoch [52/100], Loss: 0.1275, Val Loss: 0.6298\n",
            "Epoch [53/100], Loss: 0.0224, Val Loss: 0.6418\n",
            "Epoch [54/100], Loss: 0.0568, Val Loss: 0.6358\n",
            "Epoch [55/100], Loss: 0.0082, Val Loss: 0.6211\n",
            "Epoch [56/100], Loss: 0.0443, Val Loss: 0.6312\n",
            "Epoch [57/100], Loss: 0.1109, Val Loss: 0.6181\n",
            "Epoch [58/100], Loss: 0.0218, Val Loss: 0.6358\n",
            "Epoch [59/100], Loss: 0.2602, Val Loss: 0.6115\n",
            "Epoch [60/100], Loss: 0.0029, Val Loss: 0.6216\n",
            "Epoch [61/100], Loss: 0.2456, Val Loss: 0.6289\n",
            "Epoch [62/100], Loss: 0.0168, Val Loss: 0.6339\n",
            "Epoch [63/100], Loss: 0.0179, Val Loss: 0.6170\n",
            "Epoch [64/100], Loss: 0.0259, Val Loss: 0.6225\n",
            "Epoch [65/100], Loss: 0.0296, Val Loss: 0.6128\n",
            "Epoch [66/100], Loss: 0.0089, Val Loss: 0.6228\n",
            "Epoch [67/100], Loss: 0.0821, Val Loss: 0.6055\n",
            "Epoch [68/100], Loss: 0.0336, Val Loss: 0.6222\n",
            "Epoch [69/100], Loss: 0.0088, Val Loss: 0.6214\n",
            "Epoch [70/100], Loss: 0.0154, Val Loss: 0.6457\n",
            "Epoch [71/100], Loss: 0.5466, Val Loss: 0.6242\n",
            "Epoch [72/100], Loss: 0.0059, Val Loss: 0.6340\n",
            "Epoch [73/100], Loss: 0.1032, Val Loss: 0.6215\n",
            "Epoch [74/100], Loss: 0.0012, Val Loss: 0.6190\n",
            "Epoch [75/100], Loss: 0.0064, Val Loss: 0.6289\n",
            "Epoch [76/100], Loss: 0.0074, Val Loss: 0.6269\n",
            "Epoch [77/100], Loss: 0.0460, Val Loss: 0.6133\n",
            "Epoch [78/100], Loss: 0.0398, Val Loss: 0.6244\n",
            "Epoch [79/100], Loss: 0.0166, Val Loss: 0.6110\n",
            "Epoch [80/100], Loss: 0.0389, Val Loss: 0.6203\n",
            "Epoch [81/100], Loss: 0.0038, Val Loss: 0.6092\n",
            "Epoch [82/100], Loss: 0.0080, Val Loss: 0.6194\n",
            "Epoch [83/100], Loss: 0.0261, Val Loss: 0.6113\n",
            "Epoch [84/100], Loss: 0.0222, Val Loss: 0.6124\n",
            "Epoch [85/100], Loss: 0.0873, Val Loss: 0.6119\n",
            "Epoch [86/100], Loss: 0.0321, Val Loss: 0.6076\n",
            "Epoch [87/100], Loss: 0.0709, Val Loss: 0.5983\n",
            "Epoch [88/100], Loss: 0.0203, Val Loss: 0.5969\n",
            "Epoch [89/100], Loss: 0.0147, Val Loss: 0.6074\n",
            "Epoch [90/100], Loss: 0.0095, Val Loss: 0.6153\n",
            "Epoch [91/100], Loss: 0.0140, Val Loss: 0.6065\n",
            "Epoch [92/100], Loss: 0.0494, Val Loss: 0.6041\n",
            "Epoch [93/100], Loss: 0.0155, Val Loss: 0.6128\n",
            "Epoch [94/100], Loss: 0.0298, Val Loss: 0.6263\n",
            "Epoch [95/100], Loss: 0.0747, Val Loss: 0.6078\n",
            "Epoch [96/100], Loss: 0.0084, Val Loss: 0.6088\n",
            "Epoch [97/100], Loss: 0.0168, Val Loss: 0.6144\n",
            "Epoch [98/100], Loss: 0.5257, Val Loss: 0.6213\n",
            "Epoch [99/100], Loss: 0.0351, Val Loss: 0.6078\n",
            "Epoch [100/100], Loss: 0.0360, Val Loss: 0.6059\n",
            "Predicted physical capability percentages: [80.37585  70.39058  79.77243  ... 71.71443  58.341496 78.25643 ]\n"
          ]
        }
      ]
    }
  ]
}