{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ+mHaIFLBw47HV/Bhl5ch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franciscoerramuspe/masters_thesis/blob/main/WHOOP_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown --id 10bbWtKE3n1BpAYitwQxeQdfXYvpXhacZ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtlNJmOnacCq",
        "outputId": "93df3582-af72-45a4-cfd2-4fa346b594d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10bbWtKE3n1BpAYitwQxeQdfXYvpXhacZ\n",
            "To: /content/Final_Labeled_Scored_Data.xlsx\n",
            "100% 20.3M/20.3M [00:00<00:00, 52.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "file_path = '/content/Final_Labeled_Scored_Data.xlsx'\n",
        "df = pd.read_excel(file_path)\n"
      ],
      "metadata": {
        "id": "stWDthtxaiCg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjC7yuGfaWZQ",
        "outputId": "2422a868-b27b-4a75-9c06-f025e64c3779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame shape: (82811, 89)\n",
            "\n",
            "NaN values in each column:\n",
            "Activity Strain              10087\n",
            "Activity name                10087\n",
            "Altitude change (meters)     61839\n",
            "Altitude gain (meters)       61839\n",
            "Answered yes                  6620\n",
            "                             ...  \n",
            "What is your gender?           725\n",
            "Scan Date_x                   5559\n",
            "Jump - Jump Height (in)_x     5748\n",
            "Scan Date_y                  82694\n",
            "Jump - Jump Height (in)_y    82694\n",
            "Length: 89, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-97651c122e48>:59: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  return torch.FloatTensor(sequences), torch.FloatTensor(targets)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 82804 sequences\n",
            "Epoch [1/100], Loss: 0.4385, Val Loss: 1.0696\n",
            "Epoch [2/100], Loss: 0.3458, Val Loss: 0.8852\n",
            "Epoch [3/100], Loss: 0.1085, Val Loss: 0.7167\n",
            "Epoch [4/100], Loss: 0.0555, Val Loss: 0.7081\n",
            "Epoch [5/100], Loss: 0.0883, Val Loss: 0.7703\n",
            "Epoch [6/100], Loss: 0.1777, Val Loss: 0.6774\n",
            "Epoch [7/100], Loss: 0.0342, Val Loss: 0.6856\n",
            "Epoch [8/100], Loss: 0.0284, Val Loss: 0.6464\n",
            "Epoch [9/100], Loss: 0.0782, Val Loss: 0.6589\n",
            "Epoch [10/100], Loss: 0.0235, Val Loss: 0.6396\n",
            "Epoch [11/100], Loss: 0.0141, Val Loss: 0.6351\n",
            "Epoch [12/100], Loss: 0.0062, Val Loss: 0.6624\n",
            "Epoch [13/100], Loss: 0.0507, Val Loss: 0.6352\n",
            "Epoch [14/100], Loss: 0.0456, Val Loss: 0.6450\n",
            "Epoch [15/100], Loss: 0.0407, Val Loss: 0.6511\n",
            "Epoch [16/100], Loss: 0.1148, Val Loss: 0.6407\n",
            "Epoch [17/100], Loss: 0.0007, Val Loss: 0.6205\n",
            "Epoch [18/100], Loss: 0.0306, Val Loss: 0.6405\n",
            "Epoch [19/100], Loss: 0.0124, Val Loss: 0.6267\n",
            "Epoch [20/100], Loss: 0.0562, Val Loss: 0.6246\n",
            "Epoch [21/100], Loss: 0.0235, Val Loss: 0.6165\n",
            "Epoch [22/100], Loss: 0.0155, Val Loss: 0.6187\n",
            "Epoch [23/100], Loss: 0.0138, Val Loss: 0.6268\n",
            "Epoch [24/100], Loss: 0.0146, Val Loss: 0.6192\n",
            "Epoch [25/100], Loss: 0.0093, Val Loss: 0.6139\n",
            "Epoch [26/100], Loss: 0.0160, Val Loss: 0.6278\n",
            "Epoch [27/100], Loss: 0.0115, Val Loss: 0.6341\n",
            "Epoch [28/100], Loss: 0.0341, Val Loss: 0.6307\n",
            "Epoch [29/100], Loss: 0.0048, Val Loss: 0.6413\n",
            "Epoch [30/100], Loss: 0.0297, Val Loss: 0.6111\n",
            "Epoch [31/100], Loss: 0.0234, Val Loss: 0.6339\n",
            "Epoch [32/100], Loss: 0.0464, Val Loss: 0.6249\n",
            "Epoch [33/100], Loss: 0.0130, Val Loss: 0.6180\n",
            "Epoch [34/100], Loss: 0.0844, Val Loss: 0.6460\n",
            "Epoch [35/100], Loss: 0.0539, Val Loss: 0.6308\n",
            "Epoch [36/100], Loss: 0.0364, Val Loss: 0.6270\n",
            "Epoch [37/100], Loss: 0.0314, Val Loss: 0.6257\n",
            "Epoch [38/100], Loss: 0.0640, Val Loss: 0.6335\n",
            "Epoch [39/100], Loss: 0.0272, Val Loss: 0.6208\n",
            "Epoch [40/100], Loss: 0.0655, Val Loss: 0.6192\n",
            "Epoch [41/100], Loss: 0.1428, Val Loss: 0.6432\n",
            "Epoch [42/100], Loss: 0.1042, Val Loss: 0.6309\n",
            "Epoch [43/100], Loss: 0.0773, Val Loss: 0.6276\n",
            "Epoch [44/100], Loss: 0.0864, Val Loss: 0.6276\n",
            "Epoch [45/100], Loss: 0.0710, Val Loss: 0.6342\n",
            "Epoch [46/100], Loss: 0.0504, Val Loss: 0.6286\n",
            "Epoch [47/100], Loss: 0.0906, Val Loss: 0.6165\n",
            "Epoch [48/100], Loss: 0.0852, Val Loss: 0.6313\n",
            "Epoch [49/100], Loss: 0.0675, Val Loss: 0.6562\n",
            "Epoch [50/100], Loss: 0.0431, Val Loss: 0.6416\n",
            "Epoch [51/100], Loss: 0.0097, Val Loss: 0.6318\n",
            "Epoch [52/100], Loss: 0.0183, Val Loss: 0.6497\n",
            "Epoch [53/100], Loss: 0.0657, Val Loss: 0.6336\n",
            "Epoch [54/100], Loss: 0.0730, Val Loss: 0.6327\n",
            "Epoch [55/100], Loss: 0.1008, Val Loss: 0.6598\n",
            "Epoch [56/100], Loss: 0.1051, Val Loss: 0.6318\n",
            "Epoch [57/100], Loss: 0.2756, Val Loss: 0.6871\n",
            "Epoch [58/100], Loss: 0.0610, Val Loss: 0.6392\n",
            "Epoch [59/100], Loss: 0.0627, Val Loss: 0.6417\n",
            "Epoch [60/100], Loss: 0.0624, Val Loss: 0.6366\n",
            "Epoch [61/100], Loss: 0.1298, Val Loss: 0.6695\n",
            "Epoch [62/100], Loss: 0.1297, Val Loss: 0.6417\n",
            "Epoch [63/100], Loss: 0.0607, Val Loss: 0.6348\n",
            "Epoch [64/100], Loss: 0.0901, Val Loss: 0.6255\n",
            "Epoch [65/100], Loss: 0.0993, Val Loss: 0.6314\n",
            "Epoch [66/100], Loss: 0.0409, Val Loss: 0.6499\n",
            "Epoch [67/100], Loss: 0.0563, Val Loss: 0.6497\n",
            "Epoch [68/100], Loss: 0.0750, Val Loss: 0.6439\n",
            "Epoch [69/100], Loss: 0.0780, Val Loss: 0.6299\n",
            "Epoch [70/100], Loss: 0.1376, Val Loss: 0.6551\n",
            "Epoch [71/100], Loss: 0.0528, Val Loss: 0.6477\n",
            "Epoch [72/100], Loss: 0.0815, Val Loss: 0.6251\n",
            "Epoch [73/100], Loss: 0.0863, Val Loss: 0.6435\n",
            "Epoch [74/100], Loss: 0.1049, Val Loss: 0.6510\n",
            "Epoch [75/100], Loss: 0.1182, Val Loss: 0.6264\n",
            "Epoch [76/100], Loss: 0.0861, Val Loss: 0.6564\n",
            "Epoch [77/100], Loss: 0.1693, Val Loss: 0.6580\n",
            "Epoch [78/100], Loss: 0.1040, Val Loss: 0.6417\n",
            "Epoch [79/100], Loss: 0.1528, Val Loss: 0.6511\n",
            "Epoch [80/100], Loss: 0.1278, Val Loss: 0.6652\n",
            "Epoch [81/100], Loss: 0.0371, Val Loss: 0.6206\n",
            "Epoch [82/100], Loss: 0.0709, Val Loss: 0.6353\n",
            "Epoch [83/100], Loss: 0.1240, Val Loss: 0.6192\n",
            "Epoch [84/100], Loss: 0.0736, Val Loss: 0.6511\n",
            "Epoch [85/100], Loss: 0.1251, Val Loss: 0.6265\n",
            "Epoch [86/100], Loss: 0.0915, Val Loss: 0.6342\n",
            "Epoch [87/100], Loss: 0.0638, Val Loss: 0.6238\n",
            "Epoch [88/100], Loss: 0.0756, Val Loss: 0.6412\n",
            "Epoch [89/100], Loss: 0.1031, Val Loss: 0.6417\n",
            "Epoch [90/100], Loss: 0.0864, Val Loss: 0.6696\n",
            "Epoch [91/100], Loss: 0.0698, Val Loss: 0.6550\n",
            "Epoch [92/100], Loss: 0.0925, Val Loss: 0.6431\n",
            "Epoch [93/100], Loss: 0.1414, Val Loss: 0.6226\n",
            "Epoch [94/100], Loss: 0.0885, Val Loss: 0.6408\n",
            "Epoch [95/100], Loss: 0.0848, Val Loss: 0.6352\n",
            "Epoch [96/100], Loss: 0.1039, Val Loss: 0.6512\n",
            "Epoch [97/100], Loss: 0.0854, Val Loss: 0.6397\n",
            "Epoch [98/100], Loss: 0.1396, Val Loss: 0.6233\n",
            "Epoch [99/100], Loss: 0.0507, Val Loss: 0.6638\n",
            "Epoch [100/100], Loss: 0.0388, Val Loss: 0.6391\n",
            "Predicted physical capability percentages: [80.46601 70.70413 79.82195 ... 71.83271 58.26984 78.38659]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Print DataFrame info\n",
        "print(\"DataFrame shape:\", df.shape)\n",
        "print(\"\\nNaN values in each column:\")\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Define numerical columns\n",
        "numerical_columns = ['Activity Strain', 'Altitude change (meters)', 'Altitude gain (meters)',\n",
        "                     'Asleep duration (min)_x', 'Asleep duration (min)_y', 'Average HR (bpm)_x',\n",
        "                     'Average HR (bpm)_y', 'Awake duration (min)_x', 'Awake duration (min)_y',\n",
        "                     'Blood oxygen %', 'Day Strain', 'Deep (SWS) duration (min)_x',\n",
        "                     'Deep (SWS) duration (min)_y', 'Distance (meters)', 'Duration (min)',\n",
        "                     'Energy burned (cal)_x', 'Energy burned (cal)_y', 'HR Zone 1 %', 'HR Zone 2 %',\n",
        "                     'HR Zone 3 %', 'HR Zone 4 %', 'HR Zone 5 %', 'Heart rate variability (ms)',\n",
        "                     'In bed duration (min)_x', 'In bed duration (min)_y', 'Light sleep duration (min)_x',\n",
        "                     'Light sleep duration (min)_y', 'Max HR (bpm)_x', 'Max HR (bpm)_y',\n",
        "                     'REM duration (min)_x', 'REM duration (min)_y', 'Recovery score %',\n",
        "                     'Respiratory rate (rpm)_x', 'Respiratory rate (rpm)_y', 'Resting heart rate (bpm)',\n",
        "                     'Skin temp (celsius)', 'Sleep consistency %_x', 'Sleep consistency %_y',\n",
        "                     'Sleep debt (min)_x', 'Sleep debt (min)_y', 'Sleep efficiency %_x',\n",
        "                     'Sleep efficiency %_y', 'Sleep need (min)_x', 'Sleep need (min)_y',\n",
        "                     'Sleep performance %_x', 'Sleep performance %_y', 'Jump - Jump Height (in)_x',\n",
        "                     'Jump - Jump Height (in)_y']\n",
        "\n",
        "# Create a 'physical_capability' column if it doesn't exist\n",
        "if 'physical_capability' not in df.columns:\n",
        "    df['physical_capability'] = df['Recovery score %'].fillna(0) * 0.5 + \\\n",
        "                                df['Sleep efficiency %_x'].fillna(0) * 0.3 + \\\n",
        "                                df['Average HR (bpm)_x'].fillna(0).clip(upper=100) * 0.2\n",
        "\n",
        "# Fill NaN values with column means\n",
        "for col in numerical_columns + ['physical_capability']:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "# Prepare data for MLP (flattened sequence)\n",
        "sequence_length = 7\n",
        "input_size = len(numerical_columns) * sequence_length\n",
        "\n",
        "def create_mlp_sequences(data):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        seq = data.iloc[i:i+sequence_length][numerical_columns].values.flatten()\n",
        "        target = data.iloc[i+sequence_length]['physical_capability']\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "    return torch.FloatTensor(sequences), torch.FloatTensor(targets)\n",
        "\n",
        "X, y = create_mlp_sequences(df)\n",
        "\n",
        "if len(X) == 0 or len(y) == 0:\n",
        "    raise ValueError(f\"No valid sequences created. DataFrame has {len(df)} rows, using sequence length {sequence_length}.\")\n",
        "\n",
        "print(f\"Created {len(X)} sequences\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the MLP model\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc3 = nn.Linear(hidden_size // 2, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.relu(self.fc2(out))\n",
        "        out = self.sigmoid(self.fc3(out)) * 100  # Scale output to 0-100\n",
        "        return out\n",
        "\n",
        "# Initialize the model\n",
        "hidden_size = 128\n",
        "output_size = 1\n",
        "\n",
        "model = MLPModel(input_size, hidden_size, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y.unsqueeze(1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_test)\n",
        "        val_loss = criterion(val_outputs, y_test.unsqueeze(1))\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
        "\n",
        "# Prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_output = model(X_test)\n",
        "    print(\"Predicted physical capability percentages:\", test_output.numpy().flatten())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyMWRQE_bwO0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}